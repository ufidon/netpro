{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The World Wide Web\n",
    "FPNP3e ch11\n",
    "\n",
    "\n",
    "Overview of HTTP\n",
    "---\n",
    "- Clients request documents\n",
    "- Servers respond by providing them\n",
    "- HTTP is certainly capable of delivering stand-alone documents such as \n",
    "  - files, audios, images, and video\n",
    "- The main purpose is to deliver the [World Wide Web](https://en.wikipedia.org/wiki/World_Wide_Web)\n",
    "  - allow servers all over the world to publish documents, \n",
    "  - through mutual cross-links, \n",
    "  - become a single interlinked fabric of information\n",
    "\n",
    "\n",
    "Hypermedia and URLs\n",
    "---\n",
    "- [URLs (uniform resource locators)](https://en.wikipedia.org/wiki/URL) are addresses on the web\n",
    "  - known as hyperlinks, or simply links\n",
    "  - clickable and usually highlighted with underlines\n",
    "- Hypermedia are images, sound, and video mixed with links\n",
    "- Hypertext documents contain embedded hyperlinks\n",
    "\n",
    "```html\n",
    "<!-- some sample URLs  -->\n",
    "https://www.python.org/\n",
    "http://en.wikipedia.org/wiki/Python_(programming_language)\n",
    "http://localhost:8000/headers\n",
    "ftp://ssd.jpl.nasa.gov/pub/eph/planets/README.txt\n",
    "telnet://rainmaker.wunderground.com\n",
    "\n",
    "<!-- URL with a query string -->\n",
    "https://www.google.com/search?product=ipad&bInStore=yes\n",
    "\n",
    "<!-- URL with fragment -->\n",
    "https://datatracker.ietf.org/doc/html/rfc3986#section-3.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing and Building URLs\n",
    "---\n",
    "- Every HTTP URL conforms to the syntax of a generic URI\n",
    "- The URI generic syntax consists of five components organized hierarchically \n",
    "  - in order of decreasing significance from left to right\n",
    "  ```\n",
    "  URI = scheme \":\" [\"//\" authority] path [\"?\" query] [\"#\" fragment]\n",
    "  authority = [userinfo \"@\"] host [\":\" port]\n",
    "  ``` \n",
    "\n",
    "\n",
    "🔭 Explore\n",
    "---\n",
    "- [the components of URIs](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier#Syntax)\n",
    "- [List of URI schemes](https://en.wikipedia.org/wiki/List_of_URI_schemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing URLs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PSL urllib.parse module is used to interpret and to build URLs\n",
    "from urllib.parse import urlsplit\n",
    "u = urlsplit('https://www.google.com/search?product=ipad&bInStore=yes')\n",
    "tuple(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'type: {type(u)}\\nscheme: {u.scheme}\\nnetloc: {u.netloc}\\npath: {u.path}\\nquery: {u.query}\\nfragment: {u.fragment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The “network location” netloc can have several subordinate pieces, \n",
    "# but they are uncommon enough that urlsplit()\n",
    "# does not break them out as separate items in its tuple. \n",
    "# Instead, they are available only as attributes of its result\n",
    "u = urlsplit('https://brandon:atigdng@localhost:8000/')\n",
    "print('netloc: ', u.netloc)\n",
    "print('username: ', u.username)\n",
    "print('password: ', u.password)\n",
    "print('hostname: ', u.hostname)\n",
    "print('port: ', u.port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path and query components can be decomposed further\n",
    "# &, #, and / are delimitors in URL, their literals must be escaped\n",
    "from urllib.parse import parse_qs, parse_qsl, unquote\n",
    "# http://example.com/Q&A/TCP/IP?q=packet loss&t=time elapse'\n",
    "# In Q&A, & -> %26; in TCP/IP, / -> %2F; in 'packet loss', ␣ -> +\n",
    "u = urlsplit('http://example.com/Q%26A/TCP%2FIP?q=packet+loss&t=time+elapse')\n",
    "path = [unquote(s) for s in u.path.split('/')]\n",
    "query = parse_qsl(u.query)\n",
    "\n",
    "# the initial empty string in the path components is the root path begins with a slash\n",
    "print('path components: ', path) \n",
    "\n",
    "# \n",
    "print('queries: ', query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_qsl() gives the query as a list since a query parameter can appear multiple times\n",
    "# parse_qs()  gives the query as a dictionary\n",
    "u = urlsplit('http://search.org/?q=one&q=two&p=price')\n",
    "ql = parse_qsl(u.query)\n",
    "qd = parse_qs(u.query)\n",
    "print(\"Query as list: \", ql)\n",
    "print(\"Query as dictionary: \", qd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building URLs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://example.com/Q%26A/TCP%2FIP?q=packet+loss&t=time+elapse'\n",
    "u = urlsplit(URL)\n",
    "path = [unquote(s) for s in u.path.split('/')]\n",
    "query = parse_qsl(u.query)\n",
    "\n",
    "from urllib.parse import quote, urlencode, urlunsplit\n",
    "urlunsplit((u.scheme, u.netloc, \n",
    "            '/'.join(quote(p, safe='') for p in path),\n",
    "            urlencode(query), ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Q&A/TCP IP'\n",
    "qt = quote(s)\n",
    "uq = unquote(qt)\n",
    "print((qt, uq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔭 Explore\n",
    "---\n",
    "- [urllib.parse — Parse URLs into components](https://docs.python.org/3/library/urllib.parse.html#module-urllib.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative URLs\n",
    "---\n",
    "- In filesystem, there are \n",
    "  - *absolute path* starts from the root\n",
    "  - *relative paths* start from the *current working directory*\n",
    "- Hypertext has similar hierarchy\n",
    "  - *An absolute URL* can be accessed from anywhere\n",
    "  - *Relative URLs* in a document depends on the location of the document\n",
    "    - *urljoin()* can be used to find the absolute form of a relative URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The argument order of urljoin() is the same as that of os.path.join(). \n",
    "# First the base URL of the document\n",
    "# Second the relative URL inside of it\n",
    "from urllib.parse import urljoin\n",
    "base = 'http://tools.ietf.org/html/rfc3986'\n",
    "a1 = urljoin(base, 'rfc7320')\n",
    "a2 = urljoin(base, '.')\n",
    "a3 = urljoin(base, '..')\n",
    "a4 = urljoin(base, '/dailydose/')\n",
    "a5 = urljoin(base, '?version=1.0')\n",
    "a6 = urljoin(base, '#section-5.4')\n",
    "\n",
    "# Find a1-a6 manually, then verify your answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for an absolute URL, urljoin will not modify it\n",
    "urljoin(base, 'https://www.google.com/search?q=apod&btnI=yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a relative URL can omit the scheme but specify everything else.\n",
    "# only the scheme is copied from the base URL\n",
    "urljoin(base, '//www.google.com/search?q=apod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trailing slash matters in relative URLs\n",
    "ta1 = urljoin('http://tools.ietf.org/html/rfc3986', 'rfc7320')\n",
    "ta2 = urljoin('http://tools.ietf.org/html/rfc3986/', 'rfc7320')\n",
    "print(ta1)\n",
    "print(ta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- always redirect users from a wrong URL to the correct path to create robust web applications\n",
    "- relative URLs are not necessarily relative to the path provided in the HTTP request\n",
    "- relative URLs should be constructed relative to the Location header in the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Hypertext Markup Language](https://en.wikipedia.org/wiki/HTML)\n",
    "---\n",
    "- the standard markup language for documents designed to be displayed in a web browser\n",
    "- defines the meaning and structure of web content\n",
    "- often assisted by Cascading Style Sheets (CSS) and scripting languages such as JavaScript\n",
    "\n",
    "\n",
    "🔭 Explore\n",
    "---\n",
    "- [HTML living standard](https://html.spec.whatwg.org/)\n",
    "- [CSS Snapshot](https://www.w3.org/TR/CSS/)\n",
    "- [JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)\n",
    "- [Document Object Model (DOM)](https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model)\n",
    "\n",
    "\n",
    "[Well-formed document](https://en.wikipedia.org/wiki/Well-formed_document)\n",
    "---\n",
    "- A HTML file is a well-formed document with [well-formed tags](https://en.wikipedia.org/wiki/Well-formed_element) organizing content\n",
    "  - Tags are case sensitive\n",
    "  - Content be delimited with a beginning and end tag\n",
    "  - Content be properly nested (parents within roots, children within parents)\n",
    "\n",
    "\n",
    "Tag Examples\n",
    "---\n",
    "```html\n",
    "<!-- 1. tags are properly nested -->\n",
    "<p>This is a paragraph with <b>bold</b> and <i>italic</i> words.</p>\n",
    "\n",
    "<!-- 2. self-contained tags -->\n",
    "<br> or <br/>\n",
    "\n",
    "<!-- 3.  the most generic kind of box -->\n",
    "<div> generic box </div>\n",
    "\n",
    "<!-- 4. the most generic way to mark running text -->\n",
    "<span> generic way to mark running text </span>\n",
    "```\n",
    "\n",
    "Element selectors\n",
    "---\n",
    "```html\n",
    "<div class=\"weather\">\n",
    "  <h5 class=\"city\"> Tampa </h5>\n",
    "  <p class=\"temperature\"> 26 ℃ </p>\n",
    "</div>\n",
    "\n",
    "<!-- generic class selectors -->\n",
    ".city, .temperature\n",
    "\n",
    "<!-- element class selectors -->\n",
    "h5.city, p.temperature\n",
    "\n",
    "<!-- whitespace-concatenated selectors -->\n",
    ".weather h5\n",
    ".weather p\n",
    "```\n",
    "\n",
    "🖊️ Practice\n",
    "---\n",
    "- Inspect a HTML webpage with developer tools in Firefox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and Writing to a Database \n",
    "---\n",
    "- Web applications usually have a backend database\n",
    "- e.g. a simple bank web application has a database with tables to save \n",
    "  - user accounts and bank accounts\n",
    "  - checking accounts, saving account and credit cards\n",
    "  - payments, etc.\n",
    "- the server scripts of the web app interact with the DBMS through [DB-API](https://peps.python.org/pep-0249/) \n",
    "  - defined in PEP 249 – Python Database API Specification v2.0\n",
    "  - supported by all modern Python database connectors\n",
    "  - the Python connector for SQLite is built in PSL\n",
    "\n",
    "\n",
    "🔭 Explore\n",
    "---\n",
    "- [A Routine for Building and Talking to a Database](./www/bank.py)\n",
    "- View the database created above using one of the SQLite GUI applications\n",
    "  - [SQLiteStudio](https://sqlitestudio.pl/)\n",
    "  - [DB Browser for SQLite](https://sqlitebrowser.org/)\n",
    "  - [SQLite Manager](https://addons.mozilla.org/en-US/firefox/addon/sqlite-manager-webext/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Insecure Web Application\n",
    "---\n",
    "- consists of\n",
    "  - a SQLite database *bank.db* and accessing program *bank.py*\n",
    "  - a server application: app_insecure.py\n",
    "  - 4 template files in [Jinja](https://jinja.palletsprojects.com) template language:\n",
    "    - [base.html](./www/templates/base.html) contains \n",
    "      - page title, used in element \\<title\\> and \\<h1\\>\n",
    "      - page body\n",
    "    - [login.html](./www/templates/login.html) contains\n",
    "      - a title and a form for login\n",
    "    - [index.html](./www/templates/index.html) contains\n",
    "      - flash messages\n",
    "      - a list of payments\n",
    "      - two links\n",
    "    - [pay.html](./www/templates/pay.html) contains\n",
    "      - a status and hint string *complaint*\n",
    "      - the form of payment\n",
    "  - a css style [style.css](./www/static/style.css)\n",
    "- Jinja syntax examples\n",
    "  - double-brace syntax, as in {{ username }}, defines a variable username\n",
    "  - brace-percent maneuvers like {% for %} defines code\n",
    "- Explore [the Pallets Projects](https://palletsprojects.com/)\n",
    "- [An Insecure Web Application](./www/app_insecure.py)\n",
    "  ```bash\n",
    "  # 1. install modules from Pallets Projects\n",
    "  pip install Flask Werkzeug colorama watchdog Jinja2 click MarkupSafe itsdangerous Quart\n",
    "\n",
    "  # Note: in case your installation messed up with the system-site-packages\n",
    "  # sudo apt purge python3-click python3-prompt-toolkit\n",
    "  # then rerun step 1\n",
    "  # Best practice: using a virtual environment\n",
    "  # [Virtual Environments and Packages](https://docs.python.org/3/tutorial/venv.html)\n",
    "\n",
    "  # 2. run and play with the web application\n",
    "  flask --app=app_insecure run\n",
    "  ```\n",
    "- What are the vulnerabilities in this web app?\n",
    "\n",
    "\n",
    "🔭 Explore\n",
    "---\n",
    "- [Flask web framework](https://flask.palletsprojects.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML [Forms](https://www.w3schools.com/html/html_forms.asp) and HTTP Methods \n",
    "---\n",
    "- A simple HTML form\n",
    "  ```html\n",
    "  <form action=\"/search\">\n",
    "    <label>Search: <input name=\"q\"></label>\n",
    "    <button type=\"submit\">Go</button>\n",
    "  </form>\n",
    "  ```\n",
    "- An HTML form has the default method of GET\n",
    "  - encode the input fields directly in the URL\n",
    "     - saved in browsing history\n",
    "  - suitable for sharing browsing results\n",
    "  - safe to reload, forward and back\n",
    "  ```html\n",
    "  GET /search?q=python+network+programming HTTP/1.1\n",
    "  Host: searchme.com\n",
    "  ```\n",
    "  - don't use GET to send sensitive information\n",
    "- Form inputs with method POST, PUT or DELETE do not go into the URL\n",
    "  - a simple form with method POST\n",
    "    ```html\n",
    "    <form method=\"post\" action=\"/donate\">\n",
    "      <label>Charity: <input name=\"name\"></label>\n",
    "      <label>Amount: <input name=\"dollars\"></label>\n",
    "      <button type=\"submit\">Donate</button>\n",
    "    </form>\n",
    "    ```\n",
    "  - the inputs are completely encoded in the body of request\n",
    "    ```html\n",
    "    POST /donate HTTP/1.1\n",
    "    Host: example.com\n",
    "    Content-Type: application/x-www-form-urlencoded\n",
    "    Content-Length: 39\n",
    "    \n",
    "    name=PyCon%20scholarships&dollars=35\n",
    "    ```\n",
    "  - it may be a problem to reload, forward and back on the result of a POST\n",
    "    - try these operations on the /pay form of the previous insecure web app\n",
    "    - two techniques to solve the problem:\n",
    "      - use JavaScript or HTML5 form input constraints to prevent invalid inputs\n",
    "      - redirect to another URL instead of responding simply with a 200 OK page\n",
    "  - use GET for read operations and POST for writes\n",
    "    - there are many website picked the wrong methods\n",
    "    - Could you find one?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Safe and Unsafe Cookies\n",
    "---\n",
    "- the cookies in the previous insecure web app are easy to guess\n",
    "  - it simply uses the username as the cookie\n",
    "  - which can be forged to impersonate legal users\n",
    "\n",
    "\n",
    "🖊️ Practice\n",
    "---\n",
    "- run the insecure web app\n",
    "- use Firefox *web develop tools* to investigate its cookies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An unauthenticated request gets forwarded to the /login page\n",
    "import requests\n",
    "r = requests.get('http://localhost:5000/')\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misuse a cookie\n",
    "r = requests.get('http://localhost:5000/', cookies={'username': 'brandon'})\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forge a request to steal money\n",
    "r = requests.post('http://localhost:5000/pay', \n",
    "                  {'account': 'hacker', 'dollars': 100, 'memo': 'Auto-pay'},\n",
    "                  cookies={'username': 'brandon'})\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Three safe approaches to creating nonforgeable cookies\n",
    "  - leave the cookie in plaintext but sign the cookie with a digital signature\n",
    "  - encrypt the cookie to ciphertext\n",
    "  - create a purely random string for the cookie\n",
    "    - e.g. use a standard UUID library\n",
    "    - save the cookie in a database, a [Redis](https://redis.io/) instance or other short-term storage for persistence\n",
    "\n",
    "```python\n",
    "# Flask has built-in ability to digitally sign cookies\n",
    "app.secret_key = 'saiGeij8AiS2ahleahMo5dahveixuV3J'\n",
    "\n",
    "# Flask session object uses the secret key when setting a cookie\n",
    "session['username'] = username\n",
    "session['csrf_token'] = uuid.uuid4().hex\n",
    "\n",
    "# Flask verifies the signature before trusting any cookie values\n",
    "username = session.get('username')\n",
    "```\n",
    "- Further cookie safety\n",
    "  - cookies must be transmitted in HTTPS\n",
    "  - enable the [Same-origin policy](https://en.wikipedia.org/wiki/Same-origin_policy) for web servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further vulnerabilities of the insecure web app\n",
    "---\n",
    "- also vulnerable to \n",
    "  - [cross-site scripting (XSS)](https://en.wikipedia.org/wiki/Cross-site_scripting) attack\n",
    "    - due to Jinja2 does not escape special characters automatically\n",
    "    - can be fixed with Flask *render_template()* which turns on HTML escaping \n",
    "  - [Cross-Site Request Forgery (CSRF)](https://en.wikipedia.org/wiki/Cross-site_request_forgery) attack\n",
    "    - can be fixed by supplying and checking a per-session random secret\n",
    "      - demoed in [pay2.html](./www/templates/pay2.html)\n",
    "    - CSRF protection is usually built into web frameworks or third-party plugins\n",
    "      - such as library [Flask-WTF](https://flask-wtf.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🖊️ Practice\n",
    "---\n",
    "- Go through [the improved web application](./www/app_improved.py)\n",
    "- discuss the protections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔭 Explore\n",
    "---\n",
    "- Find the features of [Django](https://www.djangoproject.com/)\n",
    "  - [Overview of Django](https://en.wikipedia.org/wiki/Django_(web_framework))\n",
    "\n",
    "\n",
    "🖊️ Practice\n",
    "---\n",
    "- Go through [Django tutorial](./django.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing a [Web Framework](https://en.wikipedia.org/wiki/Web_framework)\n",
    "---\n",
    "- [Comparison of server-side web frameworks](https://en.wikipedia.org/wiki/Comparison_of_server-side_web_frameworks)\n",
    "  - [Django](https://www.djangoproject.com/)\n",
    "    - [overview](https://en.wikipedia.org/wiki/Django_(web_framework))\n",
    "  - [Tornado](https://www.tornadoweb.org/)\n",
    "    - [overview](https://en.wikipedia.org/wiki/Tornado_(web_server))\n",
    "  - [Flask](https://flask.palletsprojects.com/)\n",
    "    - [overview](https://en.wikipedia.org/wiki/Flask_(web_framework))\n",
    "  - [Quart - a Fast Python web microframework](https://pgjones.gitlab.io/)\n",
    "  - [Bottle](https://bottlepy.org/)\n",
    "  - [Pyramid](https://www.trypyramid.com/)\n",
    "- WSGI supports only traditional HTTP which operates lockstep or half-duplex\n",
    "  - has the *[long polling problem](https://en.wikipedia.org/wiki/Push_technology)* in live content update\n",
    "    - work around with [Comet - a web application model](https://en.wikipedia.org/wiki/Comet_(programming))\n",
    "- [WebSockets](https://en.wikipedia.org/wiki/WebSocket) provides full-duplex communication channels over a single TCP connection\n",
    "  - standardized in [rfc6455](https://datatracker.ietf.org/doc/html/rfc6455)\n",
    "  - start negotiation through HTTP to switch to a new system of data framing\n",
    "  - need close coordination between clients and servers\n",
    "  - [websockets: a library for building WebSocket servers and clients in Python](https://websockets.readthedocs.io/)\n",
    "\n",
    "\n",
    "🔭 Explore\n",
    "---\n",
    "- [Building a basic chat server with Quart](https://pgjones.gitlab.io/quart/tutorials/chat_tutorial.html#chat-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Web Scraping](https://en.wikipedia.org/wiki/Web_scraping)\n",
    "---\n",
    "- also known as web harvesting, or web data extraction \n",
    "- extracts data from websites for study, statistics, etc.\n",
    "- raw scraping is NOT recommended to avoid retrieving raw HTML\n",
    "- ways besides raw scraping\n",
    "  - download datasets such as [IMDb Non-Commercial Datasets](https://developer.imdb.com/non-commercial-datasets/)\n",
    "  - access Web service APIs such as [Google maps platform](https://developers.google.com/maps)\n",
    "  - obey the Terms of Service and robots.txt\n",
    "    - robots.txt shows which URLs are designed for downloading by search engines and which should be avoided\n",
    "- challenges\n",
    "  - visit a URL more than once\n",
    "  - fall in loops forever\n",
    "\n",
    "\n",
    "Steps for web scraping\n",
    "---\n",
    "- manual investigation with browser developer tools\n",
    "  - Inspect elements, Network info, Console\n",
    "- use automation tools\n",
    "  - [web crawler programs](https://en.wikipedia.org/wiki/Web_crawler) for a whole website\n",
    "  - hindered by web-based authentication, [OAuth](https://oauth.net/), anti-crawling, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three ways for fetching pages  \n",
    "---\n",
    "- Making direct GET or POST requests using a Python library such as\n",
    "  - [urllib.request](https://docs.python.org/3/library/urllib.request.html) for simple situations\n",
    "  - the Session object from library [Requests](https://requests.readthedocs.io/)\n",
    "    - keeps up with cookies and do connection pooling\n",
    "- Using middle-ware such [Mechanize](https://mechanize.readthedocs.io/)\n",
    "  - handle form elements\n",
    "- Using a full-featured web browser such as Firefox, Chrome, etc.\n",
    "  - can be exploited headlessly with libraries such as\n",
    "    - [Selenium Webdriver library](https://selenium-python.readthedocs.io/)\n",
    "    - [ghost.py - a webkit web client written in python](https://ghost-py.readthedocs.io/)\n",
    "    - [PhantomJS - Scriptable Headless Browser](https://phantomjs.org/)\n",
    "  - they work by creating a WebKit instance\n",
    "\n",
    "\n",
    "Scraping Pages return structured data\n",
    "---\n",
    "- some web pages return data in CSV, JSON, or some other recognized data format\n",
    "  - parse with PSL or third-party libraries\n",
    "- information hidden in user-facing HTML\n",
    "  - turn off JavaScript in the browser then reload\n",
    "  - use HTML tidy programs and Python libraries\n",
    "    - [Tidy](https://www.html-tidy.org/)\n",
    "    ```python\n",
    "    # 1. BeautifulSoup\n",
    "    print(soup.prettify())\n",
    "\n",
    "    # 2. lxml\n",
    "    from lxml import etree\n",
    "    print(etree.tostring(root, pretty_print=True).decode('utf-8'))\n",
    "    ```\n",
    "- Three steps in examining HTML\n",
    "  1. parse HTML using chosen libraries\n",
    "    - hard to parse HTML documents with errors \n",
    "  2. find patterned elements with selectors\n",
    "  3. retrieve the text and attribute values of each element\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🖊️ Practice\n",
    "---\n",
    "- Scrape the payments app with [Logging In to the Payments System and Adding Up Income](./www/mscrape.py)\n",
    "  ```bash\n",
    "  # 1. install required libraries\n",
    "  pip install beautifulsoup4 requests selenium lxml\n",
    "  \n",
    "  # 2. run the payments app\n",
    "  python3 app_improved.py\n",
    "\n",
    "  # 3. run the scraper\n",
    "  # using Requests library\n",
    "  python mscrape.py http://127.0.0.1:5000/\n",
    "\n",
    "  # using Selenium and Firefox with -s option \n",
    "  # broken: https://bugs.launchpad.net/ubuntu/+source/firefox/+bug/2025268\n",
    "  python mscrape.py -s http://127.0.0.1:5000/\n",
    "\n",
    "  # using lxml library\n",
    "  python mscrape.py -l http://127.0.0.1:5000/\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔭 Explore\n",
    "---\n",
    "- [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/)\n",
    "- [lxml](https://lxml.de/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Scraping\n",
    "---\n",
    "- recursively scrape all of the URLs on a web site in which\n",
    "  - some links are loaded dynamically through JavaScript \n",
    "  - others are reached only through a form post\n",
    "- usually use web-scraping engine such as [Scrapy](https://scrapy.org/)\n",
    "  - record invoked functions and URLs to avoid revisiting\n",
    "\n",
    "\n",
    "🖊️ Practice\n",
    "---\n",
    "- Scrape websites recursively with\n",
    "  - [Simple Recursive Web Scraper That Does GET](./www/rscrape1.py)\n",
    "  - [Recursively Scraping a Web Site with Selenium](./www/rscrape2.py)\n",
    "  ```bash\n",
    "  # start the tiny site\n",
    "  sudo python3 -m http.server -d ./tinysite\n",
    "\n",
    "  # scrape the tiny site\n",
    "  # find only the two links that appear literally in the HTML\n",
    "  python rscrape1.py http://127.0.0.1:8000/\n",
    "\n",
    "  # scrape httpbin.org\n",
    "  python rscrape1.py http://httpbin.org/\n",
    "\n",
    "  # scrape the tiny site with more features\n",
    "  python rscrape2.py http://127.0.0.1:8000/\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔭 Explore\n",
    "---\n",
    "- Play with [Scrapy](https://scrapy.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
